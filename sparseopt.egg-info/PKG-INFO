Metadata-Version: 2.4
Name: sparseopt
Version: 0.1.0
Summary: A tool for optimizing sparse and irregular PyTorch models
Home-page: https://github.com/yourusername/sparseopt
Author: Your Name
Author-email: your.email@example.com
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: torch>=2.0.0
Requires-Dist: typer>=0.9.0
Requires-Dist: rich>=13.0.0
Requires-Dist: networkx>=3.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: jupyter>=1.0.0; extra == "dev"
Requires-Dist: numpy>=1.24.0; extra == "dev"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# SparseOpt

A toolkit for optimizing sparse and irregular PyTorch models using Torch.fx graph transformations.

## Overview

SparseOpt is a CLI/Python tool that optimizes sparse AI models (like GNNs or MoEs) by:
- Tracing them with `torch.fx`
- Applying simple graph-level optimizations (like node reordering and operator fusion)
- Benchmarking latency before and after optimization

It automatically skips models with dynamic control flow and prints a warning when optimization isn't possible.

## Features

- **Model Analysis**: Analyze PyTorch models to identify sparse operations and irregular computation patterns
- **Model Optimization**: Optimize models for better performance on sparse and irregular workloads
- **Benchmarking**: Benchmark model performance with support for both standard PyTorch models and Graph Neural Networks (GNNs)
- **Output Consistency**: Verify that optimized models produce the same output as the original

## Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/sparseopt.git
cd sparseopt

# Install dependencies
pip install -r requirements.txt

# For GNN model support, uncomment the torch-geometric line in requirements.txt and reinstall
pip install -r requirements.txt
```

## Usage

### Analyzing a Model

```bash
sparseopt analyze --model model.py --class MyModel
```

### Optimizing a Model

```bash
sparseopt optimize --model model.py --class MyModel --output optimized_model.py
```

For GNN models:

```bash
sparseopt optimize --model model.py --class GNNModel --output optimized_model.py --gnn
```

### Benchmarking a Model

For standard PyTorch models:

```bash
sparseopt benchmark model.py MyModel --input-shape 1 3 224 224
```

For Graph Neural Network (GNN) models:

```bash
sparseopt benchmark gnn_model.py GNNModel --gnn --num-nodes 100 --num-edges 500 --node-features 16
```

### Testing Output Consistency

```bash
python tests/test_output_match.py --model model.py --class MyModel --input input.pt --output optimized_model.pt
```

## Example Output

```
Optimization Summary Report
==================================================
Model: SimpleGCN
✓ FX Tracing: Successful
Latency Before: 1.23 ms
Latency After: 0.87 ms
Speedup: 1.41x
Optimizations Applied:
  • Reorder
  • Fuse Linear+ReLU
==================================================
```

## Sample Models

SparseOpt includes a sample FX-compatible GCN model for testing:

- `sample_models/gcn.py`: A simple GCN model that can be traced by Torch.fx
- `sample_models/gcn.pt`: The saved model
- `sample_models/gcn_input.pt`: Sample input data for the model

To generate these files:

```bash
python sample_models/gcn.py
```

## Known Limitations

- **Dynamic Control Flow**: Torch.fx cannot trace models with dynamic control flow based on tensor values (e.g., `if torch.mean(x) > 0`). Such models will be saved without optimization.
- **GNN Models**: Most GNN models use PyTorch Geometric's message passing which cannot be traced by Torch.fx. These models will be saved without optimization.
- **Custom Operations**: Custom operations that cannot be traced by Torch.fx will cause optimization to fail.

## Project Structure

- `sparseopt/`: Main package directory
  - `cli.py`: Command-line interface
  - `analyze.py`: Graph analysis tools
  - `optimize.py`: Optimization passes
  - `benchmark.py`: Performance benchmarking
  - `model_loader.py`: Model loading utilities
  - `utils.py`: Shared utilities
- `tests/`: Test suite
- `sample_models/`: Sample models for testing

## Development

1. Clone the repository
2. Install development dependencies: `pip install -e ".[dev]"`
3. Run tests: `pytest tests/`

## License

MIT 
